import os
import sys
import glob

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path ä»¥å¯¼å…¥ agent_core
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(CURRENT_DIR)))
sys.path.append(PROJECT_ROOT)

from agent_core.tools import read_file
from skills.knowledge_base.scripts.db_manager import DBManager

def chunk_text_by_lines(text, chunk_size=20, overlap=5):
    """
    æŒ‰è¡Œåˆ‡åˆ†æ–‡æœ¬ï¼Œä¿è¯è¡Œå·ç²¾å‡†ã€‚
    è¿”å›: List[dict] -> [{'text': '...', 'lines': '10-30'}]
    """
    # ç§»é™¤ read_file è¿”å›çš„ header/footer (é€šè¿‡ç®€å•çš„ split)
    lines = text.splitlines()
    
    # è¿‡æ»¤æ‰ header (--- æ–‡ä»¶å…ƒæ•°æ® ---) å’Œ footer ([SYSTEM WARNING])
    # ç®€å•ç­–ç•¥ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸ä»¥ --- å¼€å¤´çš„è¡Œä½œä¸ºå¼€å§‹ï¼Ÿ
    # æˆ–è€…ç›´æ¥ç›¸ä¿¡ linesï¼Œå› ä¸º read_file è¾“å‡ºçš„å†…å®¹ä¸»è¦æ˜¯ body
    # ä¸ºäº†ç¨³å¥ï¼Œæˆ‘ä»¬æš‚æ—¶å…¨é‡åˆ‡åˆ†ï¼ŒAgent æ£€ç´¢åˆ° header ä¹Ÿæ²¡åå¤„
    
    chunks = []
    total_lines = len(lines)
    
    for i in range(0, total_lines, chunk_size - overlap):
        end = min(i + chunk_size, total_lines)
        chunk_lines = lines[i:end]
        chunk_content = "\n".join(chunk_lines).strip()
        
        if not chunk_content: continue
        
        chunks.append({
            "text": chunk_content,
            "line_start": i + 1,
            "line_end": end
        })
        
        if end == total_lines: break
        
    return chunks

def ingest_file(file_path, collection_name="documents"):
    print(f"ğŸ“„ Processing: {file_path}")
    
    # 1. è°ƒç”¨ Core Tool è¯»å–æ–‡ä»¶ (åˆ©ç”¨å…¶å¼ºå¤§çš„è§£æèƒ½åŠ›)
    # ä¸ä½¿ç”¨ outline_onlyï¼Œç›´æ¥è¯»å…¨æ–‡ (åˆ©ç”¨æ–°ç‰¹æ€§: end_line=-1)
    # æ³¨æ„ï¼šread_file å†…éƒ¨æœ‰æˆªæ–­ä¿æŠ¤ï¼Œä½†æˆ‘ä»¬ä½œä¸ºå†…éƒ¨è°ƒç”¨ï¼Œå¸Œæœ›è¯»å…¨é‡ã€‚
    # æˆ‘ä»¬éœ€è¦ç»•è¿‡ read_file çš„ 500 è¡Œä¿æŠ¤å—ï¼Ÿ
    # æ˜¯çš„ã€‚ä½† read_file çš„å®ç°æ˜¯ end_line=-1 æ—¶é»˜è®¤æˆªæ–­ã€‚
    # æˆ‘ä»¬å¯ä»¥ loop è¯»å–ï¼Œæˆ–è€…ä¿®æ”¹ read_file çš„é€»è¾‘ã€‚
    # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å…ˆè¯»å‰ 2000 è¡Œã€‚å¦‚æœæ–‡ä»¶è¶…å¤§ï¼ŒIngest è„šæœ¬åº”è¯¥å®ç°åˆ†é¡µå¾ªç¯ã€‚
    
    full_content = ""
    start_line = 1
    page_size = 1000 # æ¯æ¬¡è¯» 1000 è¡Œ
    
    while True:
        # è°ƒç”¨ tool.invoke æˆ–è€…æ˜¯ç›´æ¥å¯¼å…¥å‡½æ•°è°ƒç”¨
        # è¿™é‡Œç›´æ¥è°ƒç”¨å‡½æ•°ï¼ˆå› ä¸ºæˆ‘ä»¬åœ¨ python è„šæœ¬é‡Œï¼‰
        # ä½† read_file æ˜¯ StructuredToolï¼Œéœ€è¦ .invoke æˆ– .func
        # ç®€å•èµ·è§ï¼Œç›´æ¥è°ƒç”¨åº•å±‚çš„ _read_docx ç­‰ï¼Ÿä¸ï¼Œé‚£æ ·ç ´åäº†å°è£…ã€‚
        # æˆ‘ä»¬ç”¨ read_file.func
        
        part = read_file.func(file_path, start_line=start_line, end_line=start_line + page_size)
        
        # å»é™¤ Header/Footer å™ªéŸ³
        # è¿™æ˜¯ä¸€ä¸ª hackï¼Œä½†æœ‰æ•ˆ
        body = part
        if "--- æ–‡ä»¶å…ƒæ•°æ® ---" in part:
            body = part.split("--- æ–‡ä»¶å…ƒæ•°æ® ---")[1].split("\n", 4)[-1] # è·³è¿‡å¤´å‡ è¡Œ
        if "[SYSTEM WARNING]" in body:
            body = body.split("[SYSTEM WARNING]")[0]
            
        full_content += body
        
        # æ£€æŸ¥æ˜¯å¦è¯»å®Œ
        if "[SYSTEM WARNING]" not in part: 
            break
        start_line += page_size
        if start_line > 10000: # å®‰å…¨ç†”æ–­
            print("âš ï¸ File too large (>10k lines), stopping.")
            break

    # 2. åˆ‡ç‰‡
    chunks = chunk_text_by_lines(full_content)
    print(f"   -> Split into {len(chunks)} chunks.")
    
    if not chunks: return

    # 3. å‘é‡åŒ– & å­˜å‚¨
    db = DBManager.get_instance()
    vectors = db.embed_documents([c['text'] for c in chunks])
    
    data = []
    for i, chunk in enumerate(chunks):
        data.append({
            "vector": vectors[i],
            "text": chunk['text'],
            "source": os.path.basename(file_path),
            "line_range": f"{chunk['line_start']}-{chunk['line_end']}",
            "type": "document"
        })
        
    # 4. å†™å…¥ DB
    tbl = db.get_table(collection_name)
    if tbl:
        tbl.add(data)
    else:
        db.create_table(collection_name, data)
        
    print(f"âœ… Ingested {len(data)} vectors to '{collection_name}'.")

def main(input_path, collection="documents"):
    if os.path.isfile(input_path):
        ingest_file(input_path, collection)
    elif os.path.isdir(input_path):
        # é€’å½’æŸ¥æ‰¾æ”¯æŒçš„æ ¼å¼
        exts = ['*.docx', '*.pdf', '*.xlsx', '*.pptx', '*.md', '*.txt']
        files = []
        for ext in exts:
            files.extend(glob.glob(os.path.join(input_path, '**', ext), recursive=True))
            
        print(f"ğŸ” Found {len(files)} files in {input_path}")
        for f in files:
            try:
                ingest_file(f, collection)
            except Exception as e:
                print(f"âŒ Error processing {f}: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python ingest.py <file_or_dir> [collection_name]")
        sys.exit(1)
    
    target = sys.argv[1]
    coll = sys.argv[2] if len(sys.argv) > 2 else "documents"
    main(target, coll)
