import operator
from typing import Annotated, List, TypedDict, Union, Dict, Any

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode

# --- 1. å®šä¹‰çŠ¶æ€ (State) ---
class AgentState(TypedDict):
    # æ¶ˆæ¯å†å²ï¼šè‡ªåŠ¨è¿½åŠ 
    messages: Annotated[List[BaseMessage], operator.add]
    # åŠ¨æ€æŠ€èƒ½æ§½ä½ï¼šè¦†ç›–æ›´æ–°
    active_skills: str

# --- 2. å®šä¹‰å·¥å…· (Tools) ---
@tool
def get_weather(city: str):
    """æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ã€‚"""
    print(f"   [ToolExec] æ­£åœ¨æŸ¥è¯¢ {city} çš„å¤©æ°”...")
    return f"{city} å¤©æ°”æ™´æœ—ï¼Œ25â„ƒ"

@tool
def activate_skill(skill_name: str):
    """æ¿€æ´»ä¸€ä¸ªç‰¹æ®ŠæŠ€èƒ½ (poet æˆ– coder)ã€‚"""
    print(f"   [ToolExec] æ­£åœ¨æ¿€æ´»æŠ€èƒ½: {skill_name}...")
    
    if skill_name == "poet":
        return "SYSTEM_INJECTION: [æŠ€èƒ½: è¯—äºº] ä½ ç°åœ¨æ˜¯æç™½è½¬ä¸–ã€‚æ‰€æœ‰å›ç­”å¿…é¡»æ˜¯ä¸ƒè¨€ç»å¥ï¼Œä¸”å¿…é¡»æŠ¼éŸµã€‚"
    elif skill_name == "coder":
        return "SYSTEM_INJECTION: [æŠ€èƒ½: ç¨‹åºå‘˜] ä½ ç°åœ¨æ˜¯ Python ä¸“å®¶ã€‚æ‰€æœ‰å›ç­”å¿…é¡»åŒ…å«ä»£ç å—ã€‚"
    else:
        return f"Error: æŠ€èƒ½ '{skill_name}' æœªæ‰¾åˆ°ã€‚"

# --- 3. æ¨¡æ‹Ÿ LLM (Mock LLM) ---
# ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬ä¸ç”¨çœŸå®çš„ API Keyï¼Œè€Œæ˜¯ç”¨è§„åˆ™æ¨¡æ‹Ÿ LLM çš„å†³ç­–
# åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œåº”è¯¥æ›¿æ¢ä¸º: llm = ChatOpenAI(model="gpt-4o").bind_tools(tools)
class MockLLM:
    def invoke(self, messages: List[BaseMessage]):
        last_msg = messages[-1]
        content = last_msg.content if isinstance(last_msg, HumanMessage) else ""
        system_prompt = next((m.content for m in messages if isinstance(m, SystemMessage)), "")
        
        print(f"\nğŸ¤– [LLM æ€è€ƒä¸­]...")
        print(f"   [Context] System Prompt é•¿åº¦: {len(system_prompt)} chars")
        if "æŠ€èƒ½" in system_prompt:
            print(f"   [Context] âš ï¸ å‘ç°æ¿€æ´»çš„æŠ€èƒ½æŒ‡ä»¤ï¼")

        # ç®€å•çš„è§„åˆ™å¼•æ“æ¨¡æ‹Ÿ LLM å†³ç­–
        if "å¤©æ°”" in content:
            # æ¨¡æ‹Ÿ LLM å†³å®šè°ƒç”¨ get_weather
            return AIMessage(
                content="",
                tool_calls=[{"name": "get_weather", "args": {"city": "åŒ—äº¬"}, "id": "call_weather_1"}]
            )
        elif "æŠ€èƒ½" in content or "æ¿€æ´»" in content:
            # æ¨¡æ‹Ÿ LLM å†³å®šè°ƒç”¨ activate_skill
            skill = "poet" if "è¯—äºº" in content else "coder"
            return AIMessage(
                content="",
                tool_calls=[{"name": "activate_skill", "args": {"skill_name": skill}, "id": "call_skill_1"}]
            )
        else:
            # æ™®é€šå¯¹è¯ï¼Œæ ¹æ® System Prompt æ¨¡æ‹Ÿä¸åŒçš„äººæ ¼å›å¤
            if "[æŠ€èƒ½: è¯—äºº]" in system_prompt:
                return AIMessage(content="åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚\nä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚")
            elif "[æŠ€èƒ½: ç¨‹åºå‘˜]" in system_prompt:
                return AIMessage(content="```python\nprint('Hello World')\n```")
            else:
                return AIMessage(content=f"æ”¶åˆ°äº†ï¼š{content}ã€‚æˆ‘æ˜¯æ™®é€šåŠ©æ‰‹ã€‚" )

# åˆå§‹åŒ– Mock LLM
llm = MockLLM()
tools = [get_weather, activate_skill]

# --- 4. å®šä¹‰èŠ‚ç‚¹é€»è¾‘ (Nodes) ---

def call_model(state: AgentState):
    """æ ¸å¿ƒæ€è€ƒèŠ‚ç‚¹ï¼šç»„è£… Prompt å¹¶è°ƒç”¨ LLM"""
    messages = state["messages"]
    active_skills = state.get("active_skills", "")
    
    # [å…³é”®] åŠ¨æ€ä¸Šä¸‹æ–‡ç¼–æ’ (Context Orchestration)
    # å¦‚æœæœ‰æ¿€æ´»çš„æŠ€èƒ½ï¼Œå°†å…¶æ³¨å…¥åˆ° System Prompt
    system_instruction = "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚"
    if active_skills:
        system_instruction += f"\n\n=== ğŸŒŸ åŠ¨æ€æŠ€èƒ½ç”Ÿæ•ˆ ===\n{active_skills}\n====================="
    
    # æ„é€ ä¸´æ—¶çš„æ¶ˆæ¯åˆ—è¡¨å‘ç»™ LLM
    # æ³¨æ„ï¼šSystemMessage æ”¾åœ¨æœ€å‰é¢
    messages_with_sys = [SystemMessage(content=system_instruction)] + messages
    
    response = llm.invoke(messages_with_sys)
    return {"messages": [response]}

def handle_skill_activation(state: AgentState):
    """ä¸“é—¨å¤„ç† activate_skill çš„èŠ‚ç‚¹ï¼Œç”¨äºæ›´æ–° active_skills çŠ¶æ€"""
    last_message = state["messages"][-1]
    
    tool_outputs = []
    new_skill_content = None
    
    for tool_call in last_message.tool_calls:
        if tool_call["name"] == "activate_skill":
            # æ‰§è¡Œå·¥å…·
            result = activate_skill.invoke(tool_call["args"])
            
            # [å…³é”®] è§£æå·¥å…·è¿”å›ï¼Œæ›´æ–°å…¨å±€çŠ¶æ€
            if "SYSTEM_INJECTION" in result:
                new_skill_content = result
                user_feedback = f"æŠ€èƒ½å·²æ¿€æ´»ï¼({tool_call['args']['skill_name']})"
            else:
                user_feedback = result
                
            tool_outputs.append(
                ToolMessage(content=user_feedback, tool_call_id=tool_call["id"])
            )
    
    # å¦‚æœæŠ€èƒ½æœ‰æ›´æ–°ï¼Œè¿”å›æ–°çš„ active_skills
    if new_skill_content:
        return {"messages": tool_outputs, "active_skills": new_skill_content}
    
    return {"messages": tool_outputs}

# --- 5. æ„å»ºå›¾ (Graph Construction) ---

workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("agent", call_model)
workflow.add_node("skill_handler", handle_skill_activation)
workflow.add_node("tools", ToolNode([get_weather]))

# è®¾ç½®å…¥å£
workflow.set_entry_point("agent")

# å®šä¹‰è·¯ç”±é€»è¾‘
def should_continue(state: AgentState):
    last_message = state["messages"][-1]
    
    # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
    if not last_message.tool_calls:
        return END
    
    # å¦‚æœæ˜¯æ¿€æ´»æŠ€èƒ½ï¼Œèµ° skill_handler
    if last_message.tool_calls[0]["name"] == "activate_skill":
        return "skill_handler"
    
    # å¦åˆ™èµ°æ™®é€šå·¥å…·
    return "tools"

# æ·»åŠ è¾¹
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "skill_handler": "skill_handler",
        "tools": "tools",
        END: END
    }
)

workflow.add_edge("skill_handler", "agent")
workflow.add_edge("tools", "agent")

app = workflow.compile()

# --- 6. è¿è¡Œæµ‹è¯• (Simulation) ---

def run_demo():
    print("ğŸš€ å¯åŠ¨ä¸» Agent (LangGraph ç‰ˆ)...")
    
    # åˆå§‹çŠ¶æ€
    current_state = {"messages": [], "active_skills": ""}
    
    # åœºæ™¯ 1: æ™®é€šå¯¹è¯
    print("--- User: æ¿€æ´»â€œè¯—äººâ€æŠ€èƒ½ ---")
    inputs = {"messages": [HumanMessage(content="å¸®æˆ‘æ¿€æ´»è¯—äººæŠ€èƒ½")]}
    # åˆå¹¶è¾“å…¥åˆ°å½“å‰çŠ¶æ€
    current_state["messages"].extend(inputs["messages"])
    
    # è¿è¡Œå›¾
    for event in app.stream(current_state, stream_mode="values"):
        # è¿™é‡Œ stream ä¼šè¿”å›æ¯ä¸€æ­¥çš„çŠ¶æ€
        last_msg = event["messages"][-1]
        # æ›´æ–°æˆ‘ä»¬æ¨¡æ‹Ÿçš„å¤–éƒ¨çŠ¶æ€
        current_state = event 
        
        if isinstance(last_msg, AIMessage) and not last_msg.tool_calls:
            print(f"ğŸ¤– Agent å›å¤: {last_msg.content}")
    
    print("\n--- User: ç°åœ¨ï¼Œå†™ä¸€é¦–å…³äº AI çš„è¯— ---")
    inputs = {"messages": [HumanMessage(content="å†™ä¸€é¦–å…³äº AI çš„è¯—")]}
    current_state["messages"].extend(inputs["messages"])
    
    for event in app.stream(current_state, stream_mode="values"):
        last_msg = event["messages"][-1]
        if isinstance(last_msg, AIMessage) and not last_msg.tool_calls:
             print(f"ğŸ¤– Agent å›å¤: {last_msg.content}")

if __name__ == "__main__":
    run_demo()
